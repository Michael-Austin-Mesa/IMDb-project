{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b33aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import personal modules\n",
    "#import prepare as prep\n",
    "#import acquire as ac\n",
    "#import datascience libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn modules including classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # Gradient Boosting Classifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier # Sklearn version of LGBM Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB  # Naive Bayes Classifier\n",
    "\n",
    "\n",
    "# Sklearn testing, evaluating, and managing model\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# additional, advanced classifiers\n",
    "from xgboost import XGBClassifier as xgb  # XG Boost Classifier\n",
    "#from lightgbm import LGBMClassifier # Light Gradient Boost Classifier\n",
    "#from catboost import CatBoostClassifier # Cat boost classifier\n",
    "\n",
    "\n",
    "# import modules from standard library\n",
    "from time import time\n",
    "from pprint import pprint # pretty print\n",
    "from importlib import reload\n",
    "import os\n",
    "\n",
    "\n",
    "# NLP related modules / libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk #Natural Language Tool Kit\n",
    "import re   #Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bb8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data():\n",
    "    \n",
    "    df = get_df()\n",
    "    \n",
    "    x = df['lemmatized']\n",
    "    y = df['language']\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    #x_vectorized = cv.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 7)\n",
    "    \n",
    "    x_train = cv.fit_transform(x_train)\n",
    "    x_test = cv.transform(x_test)\n",
    "    \n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bac97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_prep_wc.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827a4cd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "      <td>listening conversation doctor parents 10yearol...</td>\n",
       "      <td>listening conversation doctor parent 10yearold...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "      <td>brother sister past incestuous relationship cu...</td>\n",
       "      <td>brother sister past incestuous relationship cu...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "      <td>bus empties students field trip museum natural...</td>\n",
       "      <td>bus empty student field trip museum natural hi...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "      <td>help unemployed father make ends meet edith tw...</td>\n",
       "      <td>help unemployed father make end meet edith twi...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-re...</td>\n",
       "      <td>film ' title refers unrecovered bodies ground ...</td>\n",
       "      <td>film  title refers unrecovered body ground zer...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54210</th>\n",
       "      <td>\"Bonino\" (1953)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>This short-lived NBC live sitcom centered on ...</td>\n",
       "      <td>shortlived nbc live sitcom centered bonino wor...</td>\n",
       "      <td>shortlived nbc live sitcom centered bonino wor...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54211</th>\n",
       "      <td>Dead Girls Don't Cry (????)</td>\n",
       "      <td>horror</td>\n",
       "      <td>The NEXT Generation of EXPLOITATION. The sist...</td>\n",
       "      <td>next generation exploitation sisters kapa bay ...</td>\n",
       "      <td>next generation exploitation sister kapa bay s...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54212</th>\n",
       "      <td>Ronald Goedemondt: Ze bestaan echt (2008)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>Ze bestaan echt, is a stand-up comedy about g...</td>\n",
       "      <td>ze bestaan echt standup comedy growing facing ...</td>\n",
       "      <td>ze bestaan echt standup comedy growing facing ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54213</th>\n",
       "      <td>Make Your Own Bed (1944)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Walter and Vivian live in the country and hav...</td>\n",
       "      <td>walter vivian live country difficult time keep...</td>\n",
       "      <td>walter vivian live country difficult time keep...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54214</th>\n",
       "      <td>Nature's Fury: Storm of the Century (2006)</td>\n",
       "      <td>history</td>\n",
       "      <td>On Labor Day Weekend, 1935, the most intense ...</td>\n",
       "      <td>labor day weekend 1935 intense hurricane ever ...</td>\n",
       "      <td>labor day weekend 1935 intense hurricane ever ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54214 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title          Genre  \\\n",
       "ID                                                                   \n",
       "1                     Oscar et la dame rose (2009)          drama    \n",
       "2                                     Cupid (1997)       thriller    \n",
       "3                 Young, Wild and Wonderful (1980)          adult    \n",
       "4                            The Secret Sin (1915)          drama    \n",
       "5                           The Unrecovered (2007)          drama    \n",
       "...                                             ...            ...   \n",
       "54210                              \"Bonino\" (1953)         comedy    \n",
       "54211                  Dead Girls Don't Cry (????)         horror    \n",
       "54212    Ronald Goedemondt: Ze bestaan echt (2008)    documentary    \n",
       "54213                     Make Your Own Bed (1944)         comedy    \n",
       "54214   Nature's Fury: Storm of the Century (2006)        history    \n",
       "\n",
       "                                             Description  \\\n",
       "ID                                                         \n",
       "1       Listening in to a conversation between his do...   \n",
       "2       A brother and sister with a past incestuous r...   \n",
       "3       As the bus empties the students for their fie...   \n",
       "4       To help their unemployed father make ends mee...   \n",
       "5       The film's title refers not only to the un-re...   \n",
       "...                                                  ...   \n",
       "54210   This short-lived NBC live sitcom centered on ...   \n",
       "54211   The NEXT Generation of EXPLOITATION. The sist...   \n",
       "54212   Ze bestaan echt, is a stand-up comedy about g...   \n",
       "54213   Walter and Vivian live in the country and hav...   \n",
       "54214   On Labor Day Weekend, 1935, the most intense ...   \n",
       "\n",
       "                                                   clean  \\\n",
       "ID                                                         \n",
       "1      listening conversation doctor parents 10yearol...   \n",
       "2      brother sister past incestuous relationship cu...   \n",
       "3      bus empties students field trip museum natural...   \n",
       "4      help unemployed father make ends meet edith tw...   \n",
       "5      film ' title refers unrecovered bodies ground ...   \n",
       "...                                                  ...   \n",
       "54210  shortlived nbc live sitcom centered bonino wor...   \n",
       "54211  next generation exploitation sisters kapa bay ...   \n",
       "54212  ze bestaan echt standup comedy growing facing ...   \n",
       "54213  walter vivian live country difficult time keep...   \n",
       "54214  labor day weekend 1935 intense hurricane ever ...   \n",
       "\n",
       "                                              lemmatized  word_count  \n",
       "ID                                                                    \n",
       "1      listening conversation doctor parent 10yearold...          51  \n",
       "2      brother sister past incestuous relationship cu...          15  \n",
       "3      bus empty student field trip museum natural hi...          56  \n",
       "4      help unemployed father make end meet edith twi...         108  \n",
       "5      film  title refers unrecovered body ground zer...          57  \n",
       "...                                                  ...         ...  \n",
       "54210  shortlived nbc live sitcom centered bonino wor...          50  \n",
       "54211  next generation exploitation sister kapa bay s...          76  \n",
       "54212  ze bestaan echt standup comedy growing facing ...          19  \n",
       "54213  walter vivian live country difficult time keep...          62  \n",
       "54214  labor day weekend 1935 intense hurricane ever ...          31  \n",
       "\n",
       "[54214 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b74872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " drama           13613\n",
       " documentary     13096\n",
       " comedy           7447\n",
       " short            5073\n",
       " horror           2204\n",
       " thriller         1591\n",
       " action           1315\n",
       " western          1032\n",
       " reality-tv        884\n",
       " family            784\n",
       " adventure         775\n",
       " music             731\n",
       " romance           672\n",
       " sci-fi            647\n",
       " adult             590\n",
       " crime             505\n",
       " animation         498\n",
       " sport             432\n",
       " talk-show         391\n",
       " fantasy           323\n",
       " mystery           319\n",
       " musical           277\n",
       " biography         265\n",
       " history           243\n",
       " game-show         194\n",
       " news              181\n",
       " war               132\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8fdaf",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9ae0b",
   "metadata": {},
   "source": [
    "### Baseline model selects drama as the most chosen genre\n",
    "\n",
    "\n",
    "### Baseline accuracy is 25.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d2d54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " drama     0.251098\n",
       "Name: Genre, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Genre == ' drama '].Genre.value_counts()/train.Genre.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45af4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_model_tests():\n",
    "    NB_training()\n",
    "    gb_training()\n",
    "    xgb_training()\n",
    "\n",
    "\n",
    "def get_df():\n",
    "    \n",
    "    if os.path.isfile('prepared_data.csv'):\n",
    "        return pd.read_csv('prepared_data.csv', index_col=[0])\n",
    "    else:\n",
    "        df = pd.read_csv('clean_scraped_data.csv', index_col=[0])\n",
    "        df = prep.map_other_languages(df)\n",
    "        \n",
    "        df.to_csv('prepared_data.csv', index=False)\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "def get_xy():\n",
    "    df = get_df()\n",
    "        \n",
    "    x = df['lemmatized']\n",
    "    y = df['language']\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    x_vectorized = cv.fit_transform(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    return x_vectorized, y\n",
    "\n",
    "\n",
    "def get_split_data():\n",
    "    \n",
    "    df = get_df()\n",
    "    \n",
    "    x = df['lemmatized']\n",
    "    y = df['language']\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    #x_vectorized = cv.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 7)\n",
    "    \n",
    "    x_train = cv.fit_transform(x_train)\n",
    "    x_test = cv.transform(x_test)\n",
    "    \n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "############         Model Collection      ##############\n",
    "  ######  Models used with hyperparameter tuning  ######\n",
    "########################################################\n",
    "\n",
    "#########################################################################\n",
    "           ############       Random Forest       ##############     \n",
    "  ######  Creates N number of trees using random starting values  ######\n",
    "########################################################################\n",
    "\n",
    "def random_forest_model(x, y):\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        min_samples_leaf=10,\n",
    "        n_estimators=200,\n",
    "        max_depth=5, \n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1,\n",
    "        max_features='auto'\n",
    "    )\n",
    "\n",
    "    rf_classifier.fit(x, y)\n",
    "\n",
    "    y_preds = rf_classifier.predict(x)\n",
    "    \n",
    "    return y_preds\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "    ############       Gradient Boosting Classifier       ##############     \n",
    "######  Creates a random forest where each tree learns from the last  ######\n",
    "############################################################################\n",
    "\n",
    "def gradient_booster_model(x_train, y_train, x_test = 0, y_test = 0, test = False):\n",
    "\n",
    "    gradient_booster = GradientBoostingClassifier(\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth = 5,\n",
    "                            n_estimators=200)\n",
    "    if test == False:\n",
    "    \n",
    "        gradient_booster.fit(x_train, y_train)\n",
    "        y_preds = gradient_booster.predict(x_train)\n",
    "        \n",
    "        return y_preds\n",
    "\n",
    "    if test == True:\n",
    "        gradient_booster.fit(x_train, y_train)\n",
    "        y_preds = gradient_booster.predict(x_test)\n",
    "\n",
    "        return y_preds\n",
    "\n",
    "#################################################################\n",
    "############         XG Boosting Classifier       ##############     \n",
    "    #######       Uses XG Boosting Algorthm       #######\n",
    "#################################################################\n",
    "\n",
    "def xgboost_model(x_train, y_train, x_test = 0, y_test = 0, test = False):\n",
    "\n",
    "    xgb_params = {'max_depth'       : 3,\n",
    "                  'eta'             : 0.01,\n",
    "                  'silent'          : 0,\n",
    "                  'eval_metric'     : 'auc',\n",
    "                  'subsample'       : 0.8,\n",
    "                  'colsample_bytree': 0.8,\n",
    "                  'objective'       : 'binary:logistic'}\n",
    "\n",
    "    \n",
    "    xgboost = xgb(params = xgb_params,\n",
    "                 num_boost_round = 2000,\n",
    "                 verbose_eval = 50,\n",
    "                 #early_stopping_rounds = 500,\n",
    "                 #feval = f1_score_cust,\n",
    "                 #evals = evals,\n",
    "                 maximize = True)\n",
    "    xgboost.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    if test == False:\n",
    "        y_preds = xgboost.predict(x_train)\n",
    "\n",
    "        return y_preds\n",
    "\n",
    "    if test == True:\n",
    "        y_preds = xgboost.predict(x_test)\n",
    "\n",
    "        return y_preds\n",
    "    \n",
    "\n",
    "#################################################################\n",
    "#########         LightGMB Boosting Classifier       ###########     \n",
    "#######       Uses Light Gradient Boosting Algorthm       #######\n",
    "#################################################################\n",
    "\n",
    "def lgmboost_model(x, y):\n",
    "    \n",
    "    lgmboost = LGBMClassifier(\n",
    "                learning_rate=0.1,\n",
    "                max_depth = 5,\n",
    "                n_estimators=200)\n",
    "\n",
    "    lgmboost.fit(x, y)\n",
    "    \n",
    "    y_preds = lgmboost.predict(x)\n",
    "    \n",
    "    return y_preds\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#########       HistGradientBoosting Classifier      ###########     \n",
    "#######    Inspired by Light Gradient Boosting Algorthm    ######\n",
    "#################################################################\n",
    "\n",
    "def histgradientboost_model(x_train, y_train, x_test = 0, y_test = 0, test = False):\n",
    "    \n",
    "    HGboost = HistGradientBoostingClassifier(\n",
    "                                            learning_rate=0.1,\n",
    "                                            max_depth = 5)\n",
    "   \n",
    "    HGboost.fit(x_train, y_train)\n",
    "    \n",
    "    if test == False:\n",
    "        y_preds = HGBoost.predict(x_train)\n",
    "        \n",
    "        return y_preds\n",
    "        \n",
    "    if test == True:\n",
    "        y_preds = HGBoost.predict(x_test)\n",
    "    \n",
    "        return y_preds\n",
    "\n",
    "\n",
    "##########################################################\n",
    "#########          Cat Boost Classifier        ###########     \n",
    "#######      Cat Boost Gradient Boosting Algorthm       ##\n",
    "##########################################################\n",
    "\n",
    "def catboost_model(x_train, y_train, x_test = 0, y_test = 0, test = False):\n",
    "    \n",
    "    catboost_params = {'loss_function' : 'Logloss',\n",
    "                        'eval_metric' : 'AUC',\n",
    "                        'verbose' : 200}\n",
    "                      \n",
    "    catboost = CatBoostClassifier(params = catboost_params)\n",
    "\n",
    "    catboost.fit(x_train, y_train, use_best_model = True)#, plot = True)\n",
    "    \n",
    "    if test == False:\n",
    "        y_preds = catboost.predict(x_train)        \n",
    "        return y_preds\n",
    "\n",
    "    if test == True:\n",
    "        y_preds = catboost.predict(x_test)\n",
    "        return y_preds\n",
    "\n",
    "####################################################################\n",
    "#########         Multinomial Naive Bayes Classifier     ###########     \n",
    "#######     Uses Naive Bayes as Classification Algorithm     #######\n",
    "####################################################################\n",
    "\n",
    "def nb_model(x_train, y_train, x_test = 0, y_test = 0, test = False):\n",
    "    \n",
    "    naive_bayes = MultinomialNB()\n",
    "    \n",
    "    if test == False:\n",
    "        naive_bayes.fit(x_train, y_train)\n",
    "        y_preds = naive_bayes.predict(x_train)\n",
    "\n",
    "        return y_preds\n",
    "    \n",
    "    if test == True:\n",
    "        naive_bayes.fit(x_train, y_train)\n",
    "        y_preds = naive_bayes.predict(x_test)\n",
    "\n",
    "        return y_preds\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "############         Model Testing      ##############\n",
    "  ######  Call function to test it's performance  ######\n",
    "########################################################\n",
    "\n",
    "######  Naive Bayes Model Train ######\n",
    "def NB_training():\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = get_split_data()\n",
    "    \n",
    "    NB_y_preds_train = nb_model(x_train, y_train)\n",
    "    report = classification_report(y_train, NB_y_preds_train)\n",
    "    print('Naive Bayes train')\n",
    "    print(report)\n",
    "\n",
    "######  Naive Bayes Model Test  ######\n",
    "def NB_test():\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = get_split_data()\n",
    "    \n",
    "    NB_y_preds_test = nb_model(x_train, y_train, x_test, y_test, test = True)\n",
    "    report = classification_report(y_test, NB_y_preds_test)\n",
    "    print('Naive Bayes test')\n",
    "    print(report)\n",
    "\n",
    "\n",
    "######  Gradient Booster Model Train ######\n",
    "\n",
    "def gb_training():\n",
    "\n",
    "    x_train, y_train, x_test, y_test = get_split_data()\n",
    "    gb_y_preds_train = gradient_booster_model(x_train, y_train)\n",
    "    report = classification_report(y_train, gb_y_preds_train)\n",
    "    print('SKLearn Gradient Booster train')\n",
    "    print(report)\n",
    "\n",
    "\n",
    "######  Gradient Booster Model Test  ######\n",
    "def gb_test():\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = get_split_data()\n",
    "    \n",
    "    gb_y_preds_test = gradient_booster_model(x_train, y_train, x_test, y_test, test = True)\n",
    "    report = classification_report(y_test, gb_y_preds_test)\n",
    "    print('SKLearn Gradient Booster test')\n",
    "    print(report)\n",
    "\n",
    "######  Extreme Gradient Boosting Model Train ######\n",
    "\n",
    "def xgb_training():\n",
    "\n",
    "    df = get_df()\n",
    "    df['language'] = df['language'].map({'Python': 3, 'Other': 2, 'Java' : 0, 'JavaScript' : 1})\n",
    "\n",
    "    x = df['lemmatized']\n",
    "    y = df['language']\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 7)\n",
    "\n",
    "    x_train = cv.fit_transform(x_train)\n",
    "    x_test = cv.transform(x_test)\n",
    "\n",
    "    xgb_preds_train = xgboost_model(x_train, y_train)\n",
    "    report = classification_report(y_train, xgb_preds_train)\n",
    "    print('Extreme Gradient Boosting training')\n",
    "    print(report)\n",
    "\n",
    "\n",
    "######  Extreme Gradient Boosting Model Test  ######\n",
    "def xgb_test():\n",
    "\n",
    "    df = get_df()\n",
    "    df['language'] = df['language'].map({'Python': 3, 'Other': 2, 'Java' : 0, 'JavaScript' : 1})\n",
    "\n",
    "    x = df['lemmatized']\n",
    "    y = df['language']\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 7)\n",
    "\n",
    "    x_train = cv.fit_transform(x_train)\n",
    "    x_test = cv.transform(x_test)\n",
    "\n",
    "    xgb_preds_test = xgboost_model(x_train, y_train, x_test, y_test, test = True)\n",
    "    report = classification_report(y_test, xgb_preds_test)\n",
    "    print('Extreme Gradient Boosting test')\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b7b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
